{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91a83a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "A=pd.read_csv(\"Dataset\\Kan\\kannada_sentiment_full_dev.tsv\",sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f239c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=pd.read_csv(\"Dataset\\Kan\\kannada_sentiment_full_train.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23e8fa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binduge saryagi ugithidira good go ahead  we a...</td>\n",
       "      <td>Mixed feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yen song guru ...super</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my fevorat story</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super ‡≤§‡≥ã‡≤ó‡≤∞‡≤ø ‡≤§‡≥Ä‡≤™‡≥ç‡≤™</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤æ‡≤§‡≥Å‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤∂‡≤É ‡≤∏‡≤§‡≥ç‡≤Ø... ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤à ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>@Nandi Parthasarathi ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Ö‡≤™‡≥ç‡≤™ ‡≤¶‡≥ä‡≤°‡≥ç ‡≤ó‡≤æ‡≤Ç‡≤°‡≥Å ‡≤∏‡≥Ç‡≤≥‡≥Ü‡≤Æ‡≤ó</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Hugi guru badethawke</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Trending no.1 wow</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>@Troll Stupid Fans naanu adikke kano helthirod...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>@JustAn Opinion ninu Tika mucchu...Evattu Kann...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text        category\n",
       "0    Binduge saryagi ugithidira good go ahead  we a...  Mixed feelings\n",
       "1                               yen song guru ...super        Positive\n",
       "2                                     my fevorat story     not-Kannada\n",
       "3                                    Super ‡≤§‡≥ã‡≤ó‡≤∞‡≤ø ‡≤§‡≥Ä‡≤™‡≥ç‡≤™        Positive\n",
       "4    ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤æ‡≤§‡≥Å‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤∂‡≤É ‡≤∏‡≤§‡≥ç‡≤Ø... ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤à ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø ...        Positive\n",
       "..                                                 ...             ...\n",
       "686  @Nandi Parthasarathi ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Ö‡≤™‡≥ç‡≤™ ‡≤¶‡≥ä‡≤°‡≥ç ‡≤ó‡≤æ‡≤Ç‡≤°‡≥Å ‡≤∏‡≥Ç‡≤≥‡≥Ü‡≤Æ‡≤ó        Negative\n",
       "687                               Hugi guru badethawke        Negative\n",
       "688                                  Trending no.1 wow        Positive\n",
       "689  @Troll Stupid Fans naanu adikke kano helthirod...        Positive\n",
       "690  @JustAn Opinion ninu Tika mucchu...Evattu Kann...        Positive\n",
       "\n",
       "[691 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "362bb24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥á‡≤∂‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤Ü‡≤∞‡≥ç‡≤•‡≤ø‡≤ï ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤°‡≥à‡≤≤‡≤ø ‡≤ü‡≥Ü‡≤ï‡≥ç ‡≤Ö‡≤™‡≥ç‡≤°‡≥á‡≤ü‡≥ç‡≤∏‡≥ç ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤∏‡≤¨‡≥ç‡≤∏‡≥ç‡≤ï‡≥ç‡≤∞...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super sar song</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tiktokers present situation... n‡≤®‡≥ã‡≤°‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤Ø‡≤æ‡≤∞‡≥Å ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç ‡≤µ‡≥Ü‡≤∞‡≤ø ‡≤®‡≥à‡≤∏‡≥ç....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>@A.R.W   tumbad tanhaji andhadhun aise bahot h...</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>‡¥™‡µä‡¥≥‡¥ø ‡¥°‡¥æ‡µª‡¥∏‡µçü•∞ ‡¥∞‡¥ï‡µç‡¥∑‡¥ø‡¥§‡µç ‡¥∑‡µÜ‡¥ü‡µç‡¥ü‡¥ø ‡¥Æ‡¥æ‡¥∏‡µç‡¥∏‡µç</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>Bro...nNeen este Roast madudru...China ne beku...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6210</th>\n",
       "      <td>‡≤ï‡≥å‡≤∂‡≤≤‡≥ç‡≤Ø ‡≤á‡≤¶‡≥ç‡≤¶‡≤µ‡≤∞ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤ï‡≤°‡≤ø‡≤Æ‡≥Ü ‡≤á‡≤≤‡≥ç‡≤≤ ‡≤∏‡≤∞‡≥ç ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤™‡≥ç‡≤∞‡≤§...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>26 M Views</td>\n",
       "      <td>Mixed feelings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6212 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        category\n",
       "0     ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥á‡≤∂‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤Ü‡≤∞‡≥ç‡≤•‡≤ø‡≤ï ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®...        Negative\n",
       "1     ‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤°‡≥à‡≤≤‡≤ø ‡≤ü‡≥Ü‡≤ï‡≥ç ‡≤Ö‡≤™‡≥ç‡≤°‡≥á‡≤ü‡≥ç‡≤∏‡≥ç ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤∏‡≤¨‡≥ç‡≤∏‡≥ç‡≤ï‡≥ç‡≤∞...        Positive\n",
       "2                                        Super sar song     not-Kannada\n",
       "3     Tiktokers present situation... n‡≤®‡≥ã‡≤°‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤Ø‡≤æ‡≤∞‡≥Å ...        Negative\n",
       "4                             Super ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç ‡≤µ‡≥Ü‡≤∞‡≤ø ‡≤®‡≥à‡≤∏‡≥ç....        Positive\n",
       "...                                                 ...             ...\n",
       "6207  @A.R.W   tumbad tanhaji andhadhun aise bahot h...     not-Kannada\n",
       "6208                  ‡¥™‡µä‡¥≥‡¥ø ‡¥°‡¥æ‡µª‡¥∏‡µçü•∞ ‡¥∞‡¥ï‡µç‡¥∑‡¥ø‡¥§‡µç ‡¥∑‡µÜ‡¥ü‡µç‡¥ü‡¥ø ‡¥Æ‡¥æ‡¥∏‡µç‡¥∏‡µç     not-Kannada\n",
       "6209  Bro...nNeen este Roast madudru...China ne beku...        Negative\n",
       "6210  ‡≤ï‡≥å‡≤∂‡≤≤‡≥ç‡≤Ø ‡≤á‡≤¶‡≥ç‡≤¶‡≤µ‡≤∞ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤ï‡≤°‡≤ø‡≤Æ‡≥Ü ‡≤á‡≤≤‡≥ç‡≤≤ ‡≤∏‡≤∞‡≥ç ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤™‡≥ç‡≤∞‡≤§...        Positive\n",
       "6211                                         26 M Views  Mixed feelings\n",
       "\n",
       "[6212 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36839979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb3024b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6212, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40798bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=pd.concat([A,B],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9711ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6903, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "794aa48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mixed feelings', 'Positive', 'not-Kannada', 'Negative',\n",
       "       'unknown state'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03563b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Positive          3144\n",
       "Negative          1327\n",
       "not-Kannada       1026\n",
       "unknown state      780\n",
       "Mixed feelings     626\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e0d4581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         6903\n",
       "unique           5\n",
       "top       Positive\n",
       "freq          3144\n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[\"category\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d0f775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 6903 entries, 0 to 6902\n",
      "Series name: category\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "6903 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 54.1+ KB\n"
     ]
    }
   ],
   "source": [
    "c[\"category\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d4d11c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[\"category\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "930620f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl (105 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ------------------------ --------------- 3/5 [certifi]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.7.14 charset_normalizer-3.4.2 idna-3.10 requests-2.32.4 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20c992a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamil stopwords: 0\n",
      "Malayalam stopwords: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Download the correct raw JSON file\n",
    "url = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-iso/master/stopwords-iso.json\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Load JSON\n",
    "stopwords_data = json.loads(response.text)\n",
    "\n",
    "# Get Tamil and Malayalam stopwords\n",
    "tamil = stopwords_data.get(\"ta\", [])\n",
    "malayalam = stopwords_data.get(\"ml\", [])\n",
    "\n",
    "print(\"Tamil stopwords:\", len(tamil))\n",
    "print(\"Malayalam stopwords:\", len(malayalam))\n",
    "\n",
    "# Save to files\n",
    "with open(\"tamil_stopwords.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(tamil))\n",
    "\n",
    "with open(\"malayalam_stopwords.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(malayalam))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66ff8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url_tamil = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-ta/master/stopwords-ta.txt\"\n",
    "tamil_stopwords = requests.get(url_tamil).text\n",
    "\n",
    "with open(\"tamil_stopwords.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(tamil_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66bf2b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Tamil stopwords not found. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Tamil stopwords download\n",
    "tamil_url = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-ta/master/stopwords-ta.txt\"\n",
    "response_tamil = requests.get(tamil_url)\n",
    "\n",
    "if response_tamil.status_code == 200:\n",
    "    with open(\"tamil_stopwords.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response_tamil.text)\n",
    "    print(\"‚úÖ Tamil stopwords saved.\")\n",
    "else:\n",
    "    print(\"‚ùå Tamil stopwords not found. Status code:\", response_tamil.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bfdd1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Malayalam stopwords not found. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "# Malayalam stopwords download\n",
    "mal_url = \"https://raw.githubusercontent.com/jerinphilip/malayalam-stopwords/master/stopwords.txt\"\n",
    "response_mal = requests.get(mal_url)\n",
    "\n",
    "if response_mal.status_code == 200:\n",
    "    with open(\"malayalam_stopwords.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response_mal.text)\n",
    "    print(\"‚úÖ Malayalam stopwords saved.\")\n",
    "else:\n",
    "    print(\"‚ùå Malayalam stopwords not found. Status code:\", response_mal.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38fb3dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Malayalam stopwords not found. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Malayalam stopwords (confirmed working)\n",
    "mal_url = \"https://raw.githubusercontent.com/jerinphilip/malayalam-stopwords/master/stopwords.txt\"\n",
    "response_mal = requests.get(mal_url)\n",
    "\n",
    "if response_mal.status_code == 200:\n",
    "    with open(\"malayalam_stopwords.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response_mal.text)\n",
    "    print(\"‚úÖ Malayalam stopwords saved.\")\n",
    "else:\n",
    "    print(\"‚ùå Malayalam stopwords not found. Status code:\", response_mal.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "947f6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_url = \"https://raw.githubusercontent.com/anoopkunchukuttan/indic_nlp_resources/master/stopwords/tamil_stopwords.txt\"\n",
    "r = requests.get(ta_url)\n",
    "with open(\"tamil_stopwords.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(r.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8e7b591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Malayalam stopwords saved ‚Äì entries: 1\n"
     ]
    }
   ],
   "source": [
    "res = requests.get(\n",
    "    \"https://raw.githubusercontent.com/jerinphilip/malayalam-stopwords/master/stopwords.txt\"\n",
    ")\n",
    "with open(\"malayalam_stopwords.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(res.text)\n",
    "print(\"‚úÖ Malayalam stopwords saved ‚Äì entries:\", len(res.text.splitlines()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51b71b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting deep-translator\n",
      "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.9.1 (from deep-translator)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\dell\\anaconda3\\envs\\chipseq_env\\lib\\site-packages (from deep-translator) (2.32.4)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.13.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\chipseq_env\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\chipseq_env\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\chipseq_env\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\chipseq_env\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.7.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 936.2 kB/s eta 0:00:00\n",
      "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, soupsieve, regex, joblib, click, nltk, beautifulsoup4, deep-translator\n",
      "\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ----- ---------------------------------- 1/8 [soupsieve]\n",
      "   ---------- ----------------------------- 2/8 [regex]\n",
      "   --------------- ------------------------ 3/8 [joblib]\n",
      "   --------------- ------------------------ 3/8 [joblib]\n",
      "   --------------- ------------------------ 3/8 [joblib]\n",
      "   --------------- ------------------------ 3/8 [joblib]\n",
      "   -------------------- ------------------- 4/8 [click]\n",
      "   -------------------- ------------------- 4/8 [click]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------- -------------- 5/8 [nltk]\n",
      "   ------------------------------ --------- 6/8 [beautifulsoup4]\n",
      "   ------------------------------ --------- 6/8 [beautifulsoup4]\n",
      "   ----------------------------------- ---- 7/8 [deep-translator]\n",
      "   ---------------------------------------- 8/8 [deep-translator]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.13.4 click-8.1.8 deep-translator-1.11.4 joblib-1.5.1 nltk-3.9.1 regex-2024.11.6 soupsieve-2.7 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk deep-translator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd4e306d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated stopwords saved to malayalam_stopwords.txt\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get English stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Translate to Malayalam\n",
    "translated_stopwords = []\n",
    "for word in english_stopwords:\n",
    "    try:\n",
    "        translated = GoogleTranslator(source='en', target='ml').translate(word)\n",
    "        translated_stopwords.append(translated)\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating {word}: {e}\")\n",
    "\n",
    "# Save to file\n",
    "with open(\"malayalam_stopwords.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for word in translated_stopwords:\n",
    "        f.write(word + \"\\n\")\n",
    "\n",
    "print(\"Translated stopwords saved to malayalam_stopwords.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chipseq_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
